{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target\n",
      "[4 3 2 2 1 2 3 0 2 4 4 0 4 4 3 1 4 4 1 2 4 1 2 0 1]\n",
      "\n",
      "\n",
      "\n",
      "First Prediction\n",
      "[1 1 0 0 0 0 0 3 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3]\n",
      "Training.....\n",
      "New prediction after 0 rounds of training\n",
      "[1 1 0 0 0 0 0 3 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, True, False, False, True, False, False, False]\n",
      "\tLoss 1.609432\n",
      "New prediction after 1000 rounds of training\n",
      "[4 4 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 2 4 2]\n",
      "[True, False, True, True, False, True, False, False, True, True, True, False, True, True, False, False, True, True, False, False, True, False, True, False, False]\n",
      "\tLoss 1.435941\n",
      "New prediction after 2000 rounds of training\n",
      "[4 2 2 2 1 2 2 1 2 4 4 1 4 4 1 1 4 4 1 2 4 1 2 4 1]\n",
      "[True, False, True, True, True, True, False, False, True, True, True, False, True, True, False, True, True, True, True, True, True, True, True, False, True]\n",
      "\tLoss 1.144555\n",
      "New prediction after 3000 rounds of training\n",
      "[4 2 2 2 1 2 1 1 2 4 4 1 4 4 1 1 4 4 1 2 4 1 2 1 1]\n",
      "[True, False, True, True, True, True, False, False, True, True, True, False, True, True, False, True, True, True, True, True, True, True, True, False, True]\n",
      "\tLoss 1.113453\n",
      "New prediction after 4000 rounds of training\n",
      "[4 3 2 2 1 2 0 0 2 4 4 0 4 4 0 1 4 4 1 2 4 1 2 0 1]\n",
      "[True, True, True, True, True, True, False, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True]\n",
      "\tLoss 1.009340\n",
      "New prediction after 5000 rounds of training\n",
      "[4 3 2 2 1 2 3 0 2 4 4 0 4 4 3 1 4 4 1 2 4 1 2 0 1]\n",
      "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "\tLoss 0.929354\n",
      "New prediction after 6000 rounds of training\n",
      "[4 3 2 2 1 2 3 0 2 4 4 0 4 4 3 1 4 4 1 2 4 1 2 0 1]\n",
      "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "\tLoss 0.916127\n",
      "New prediction after 7000 rounds of training\n",
      "[4 3 2 2 1 2 3 0 2 4 4 0 4 4 3 1 4 4 1 2 4 1 2 0 1]\n",
      "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "\tLoss 0.911981\n",
      "New prediction after 8000 rounds of training\n",
      "[4 3 2 2 1 2 3 0 2 4 4 0 4 4 3 1 4 4 1 2 4 1 2 0 1]\n",
      "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "\tLoss 0.910016\n",
      "New prediction after 9000 rounds of training\n",
      "[4 3 2 2 1 2 3 0 2 4 4 0 4 4 3 1 4 4 1 2 4 1 2 0 1]\n",
      "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "\tLoss 0.908881\n",
      "New prediction after 10000 rounds of training\n",
      "[4 3 2 2 1 2 3 0 2 4 4 0 4 4 3 1 4 4 1 2 4 1 2 0 1]\n",
      "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "\tLoss 0.908146\n"
     ]
    }
   ],
   "source": [
    "# Going to base this on: https://danijar.com/introduction-to-recurrent-networks-in-tensorflow/\n",
    "# This just shows how the basic object behave, with a very simple sequence-to-sequence example\n",
    "# We'll start with just learning the identity function on an alphabet of size 28\n",
    "\n",
    "num_units = 10\n",
    "num_layers = 1\n",
    "\n",
    "seq_length = 25\n",
    "\n",
    "cells = []\n",
    "for _ in range(num_layers):\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units)  # Or LSTMCell(num_units)\n",
    "    cells.append(cell)\n",
    "cell = tf.contrib.rnn.MultiRNNCell(cells) # Stack the RNN into layers\n",
    "\n",
    "num_symbols_in_alphabet = 5\n",
    "num_output_classes = 5\n",
    "\n",
    "data = tf.placeholder(tf.float32, [None, seq_length, num_symbols_in_alphabet], name = \"data\") # [batch size, string size, distinct symbols]\n",
    "output, state = tf.nn.dynamic_rnn(cell, data, dtype=tf.float32) # Outputs have the gates applied to m to produce h\n",
    "W1 = tf.Variable(tf.random_uniform([num_units,num_output_classes],0,0.01))\n",
    "output = tf.reshape(output, [-1, num_units])\n",
    "predict = tf.nn.softmax(tf.matmul(output, W1))\n",
    "predict = tf.reshape(predict, [-1, seq_length, num_output_classes])\n",
    "\n",
    "target = tf.placeholder(tf.float32, [None, seq_length, num_output_classes], name = \"target\")\n",
    "\n",
    "# loss = tf.losses.softmax_cross_entropy(tf.gather(target, indices = seq_length - 1, axis = 1), tf.gather(predict, indices = seq_length - 1, axis = 1))\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(target, predict)\n",
    "\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "updateModel = trainer.minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "rand_sample = [random.randint(0, num_symbols_in_alphabet-1) for i in range(seq_length)]\n",
    "data_sample = [np.ndarray.tolist(np.identity(num_symbols_in_alphabet)[r:r+1][0]) for r in rand_sample]\n",
    "target_sample = data_sample # Just trying to learn the identity\n",
    "p1 = sess.run([predict], feed_dict = {data:[data_sample]})\n",
    "\n",
    "print(\"Target\")\n",
    "t = np.argmax(target_sample, axis=1)\n",
    "print(t)\n",
    "print(\"\\n\\n\")\n",
    "print(\"First Prediction\")\n",
    "print(np.argmax(p1[0][0], axis=1))\n",
    "\n",
    "print(\"\\nTraining.....\\n\")\n",
    "for i in range(10001):\n",
    "    p2, _, l = sess.run([predict, updateModel, loss], feed_dict = {data:[data_sample] , target:[target_sample]})\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(\"New prediction after %i rounds of training\" % i)\n",
    "        k = np.argmax(p2[0], axis=1)\n",
    "        print(k)\n",
    "        print([k[q] == t[q] for q in range(len(k))])\n",
    "        print(\"\\tLoss %f\" % l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
