{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implementation of the DRAW network from ArXiv 1502.04623\n",
    "# With some inspiration from Eric Jang (https://blog.evjang.com/2016/06/understanding-and-implementing.html)\n",
    "# Using with py27\n",
    "# Note that a batch size of 1 is being used here which may make the gradient too unstable and require a smaller learning rate..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "'''See: https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm # color maps\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "devices = get_available_devices()\n",
    "\n",
    "print(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MNIST_row_as_image(row):\n",
    "    arr1 = []\n",
    "    for i in range(28):\n",
    "        arr2 = []\n",
    "        for j in range(28):\n",
    "            arr2.append(row[28*i + j])\n",
    "        arr1.append(arr2)\n",
    "    return np.array(arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_get_filter_banks(center_coords_dec, sigma_dec, stride_dec, N): # NxN grid of filters\n",
    "    A,B = 28,28 # For MNIST\n",
    "    sigma_dec = tf.exp(sigma_dec) # Note: sigma_decoded is the variance not the standard deviation here\n",
    "    stride_dec = tf.exp(stride_dec) # These start as logs\n",
    "    stride = stride_dec*float(A-1)/(N-1)\n",
    "    cx = (center_coords_dec[0]+1)*(float(A+1)/2.0)\n",
    "    cy = (center_coords_dec[1]+1)*(float(B+1)/2.0)\n",
    "    center_coords = [cx, cy]\n",
    "    \n",
    "    means_of_filtersx = []\n",
    "    means_of_filtersy = []\n",
    "    normx = []\n",
    "    normy = []\n",
    "    epsilon = 0.0000001\n",
    "    for i in range(N):\n",
    "        x_mean = center_coords[0] + (i-N/2-0.5)*stride\n",
    "        y_mean = center_coords[1] + (i-N/2-0.5)*stride\n",
    "        means_of_filtersx.append(x_mean)\n",
    "        means_of_filtersy.append(y_mean)\n",
    "        normx.append(tf.maximum(tf.reduce_sum([tf.exp(-(ahat-means_of_filtersx[i])**2/(2*(sigma_dec))) for ahat in range(A)]), epsilon))\n",
    "        normy.append(tf.maximum(tf.reduce_sum([tf.exp(-(bhat-means_of_filtersy[i])**2/(2*(sigma_dec))) for bhat in range(B)]), epsilon))\n",
    "        \n",
    "    filter_bank_X = [[(tf.exp(-(a-means_of_filtersx[i])**2/(2*(sigma_dec))))/normx[i] for a in range(A)] for i in range(N)]\n",
    "    filter_bank_Y = [[(tf.exp(-(b-means_of_filtersy[i])**2/(2*(sigma_dec))))/normy[i] for b in range(B)] for i in range(N)]\n",
    "    \n",
    "    return filter_bank_X, filter_bank_Y\n",
    "\n",
    "def np_get_filter_banks(center_coords_dec, sigma_dec, stride_dec, N): # NxN grid of filters\n",
    "    A,B = 28,28 # For MNIST\n",
    "    sigma_dec = np.exp(sigma_dec) # Note: sigma_decoded is the variance not the standard deviation here\n",
    "    stride_dec = np.exp(stride_dec) # These start as logs\n",
    "    stride = stride_dec*(float(A-1))/(N-1) \n",
    "    cx = (center_coords_dec[0]+1)*(float(A+1)/2.0)\n",
    "    cy = (center_coords_dec[1]+1)*(float(B+1)/2.0)\n",
    "    center_coords = [cx, cy]\n",
    "    \n",
    "    means_of_filtersx = []\n",
    "    means_of_filtersy = []\n",
    "    normx = []\n",
    "    normy = []\n",
    "    epsilon = 0.0000001\n",
    "    for i in range(N):\n",
    "        x_mean = center_coords[0] + (i-N/2-0.5)*stride\n",
    "        y_mean = center_coords[1] + (i-N/2-0.5)*stride\n",
    "        means_of_filtersx.append(x_mean)\n",
    "        means_of_filtersy.append(y_mean)\n",
    "        normx.append(np.max([np.sum([np.exp(-(ahat-means_of_filtersx[i])**2/(2*(sigma_dec))) for ahat in range(A)]), epsilon]))\n",
    "        normy.append(np.max([np.sum([np.exp(-(bhat-means_of_filtersy[i])**2/(2*(sigma_dec))) for bhat in range(B)]), epsilon]))\n",
    "        \n",
    "    filter_bank_X = [[(np.exp(-(a-means_of_filtersx[i])**2/(2*(sigma_dec))))/normx[i] for a in range(A)] for i in range(N)]\n",
    "    filter_bank_Y = [[(np.exp(-(b-means_of_filtersy[i])**2/(2*(sigma_dec))))/normy[i] for b in range(B)] for i in range(N)]\n",
    "    \n",
    "    return filter_bank_X, filter_bank_Y, [[x,y] for x in means_of_filtersx for y in means_of_filtersy]\n",
    "\n",
    "# Test the placement\n",
    "img = mnist.train.images[10003][:]\n",
    "plt.figure()\n",
    "plt.imshow(MNIST_row_as_image(img), cmap = cm.Greys_r)\n",
    "_, _, means = np_get_filter_banks(center_coords_dec = [0,0], sigma_dec = 0, stride_dec = -3, N = 5)\n",
    "scat = plt.scatter([m[0] for m in means], [m[1] for m in means], color = 'r')\n",
    "_, _, means = np_get_filter_banks(center_coords_dec = [0,0], sigma_dec = 0, stride_dec = -2, N = 5)\n",
    "scat = plt.scatter([m[0] for m in means], [m[1] for m in means], color = 'b')\n",
    "_, _, means = np_get_filter_banks(center_coords_dec = [0,0], sigma_dec = 0, stride_dec = -1, N = 5)\n",
    "scat = plt.scatter([m[0] for m in means], [m[1] for m in means], color = 'g')\n",
    "_, _, means = np_get_filter_banks(center_coords_dec = [0,0], sigma_dec = 0, stride_dec = -0, N = 5)\n",
    "scat = plt.scatter([m[0] for m in means], [m[1] for m in means], color = 'y')\n",
    "plt.figure()\n",
    "plt.imshow(MNIST_row_as_image(img), cmap = cm.Greys_r)\n",
    "_, _, means = np_get_filter_banks(center_coords_dec = [-1,0], sigma_dec = 0, stride_dec = -3, N = 5)\n",
    "scat = plt.scatter([m[0] for m in means], [m[1] for m in means], color = 'r')\n",
    "_, _, means = np_get_filter_banks(center_coords_dec = [-1,0], sigma_dec = 0, stride_dec = -2, N = 5)\n",
    "scat = plt.scatter([m[0] for m in means], [m[1] for m in means], color = 'b')\n",
    "_, _, means = np_get_filter_banks(center_coords_dec = [-1,0], sigma_dec = 0, stride_dec = -1, N = 5)\n",
    "scat = plt.scatter([m[0] for m in means], [m[1] for m in means], color = 'g')\n",
    "_, _, means = np_get_filter_banks(center_coords_dec = [-1,0], sigma_dec = 0, stride_dec = -0, N = 5)\n",
    "scat = plt.scatter([m[0] for m in means], [m[1] for m in means], color = 'y')\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.imshow(MNIST_row_as_image(img), cmap = cm.Greys_r)\n",
    "_, _, means = np_get_filter_banks(center_coords_dec = [1,1], sigma_dec = 0, stride_dec = -3, N = 5)\n",
    "scat = plt.scatter([m[0] for m in means], [m[1] for m in means], color = 'r')\n",
    "_, _, means = np_get_filter_banks(center_coords_dec = [1,1], sigma_dec = 0, stride_dec = -2, N = 5)\n",
    "scat = plt.scatter([m[0] for m in means], [m[1] for m in means], color = 'b')\n",
    "_, _, means = np_get_filter_banks(center_coords_dec = [1,1], sigma_dec = 0, stride_dec = -1, N = 5)\n",
    "scat = plt.scatter([m[0] for m in means], [m[1] for m in means], color = 'g')\n",
    "_, _, means = np_get_filter_banks(center_coords_dec = [1,1], sigma_dec = 0, stride_dec = -0, N = 5)\n",
    "scat = plt.scatter([m[0] for m in means], [m[1] for m in means], color = 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With some inspiration from Eric Jang: https://blog.evjang.com/2016/06/understanding-and-implementing.html\n",
    "attention = True\n",
    "variational = True\n",
    "num_time_steps = 10\n",
    "num_units_enc = 15\n",
    "num_units_dec = 15\n",
    "num_latents = 10\n",
    "N_read = 5\n",
    "N_write = 5\n",
    "A = 28\n",
    "B = 28\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "DO_SHARE = False\n",
    "\n",
    "# Recorded variables\n",
    "\n",
    "canvas = [None] * num_time_steps\n",
    "center_coords_decoded = [None] * num_time_steps\n",
    "sigma_decoded = [None] * num_time_steps\n",
    "stride_decoded = [None] * num_time_steps\n",
    "gamma_decoded = [None] * num_time_steps\n",
    "center_coords_decoded_write = [None] * num_time_steps\n",
    "sigma_decoded_write = [None] * num_time_steps\n",
    "stride_decoded_write = [None] * num_time_steps\n",
    "gamma_decoded_write = [None] * num_time_steps\n",
    "lms = [None] * num_time_steps\n",
    "lss = [None] * num_time_steps\n",
    "\n",
    "# Setting up the computational graph\n",
    "\n",
    "x = tf.placeholder(shape=[batch_size, A*B],dtype=tf.float32, name = 'x')\n",
    "canvas_previous = tf.zeros(shape=[batch_size, A*B])\n",
    "\n",
    "encoder_cell = tf.contrib.rnn.LSTMBlockCell(num_units = num_units_enc)\n",
    "encoder_state_previous = encoder_cell.zero_state(batch_size, tf.float32)\n",
    "def encode_step(input_data, network_state):\n",
    "    with tf.variable_scope(\"encoder\",reuse=DO_SHARE):\n",
    "        return encoder_cell(inputs = input_data, state = network_state) # This does one cycle of the RNN\n",
    "        # This uses the __call__ method\n",
    "\n",
    "decoder_cell = tf.contrib.rnn.LSTMBlockCell(num_units = num_units_dec)\n",
    "decoder_state_previous = decoder_cell.zero_state(batch_size, tf.float32)\n",
    "def decode_step(latents, network_state):\n",
    "    with tf.variable_scope(\"decoder\",reuse=DO_SHARE):\n",
    "        return decoder_cell(inputs = latents, state = network_state) # This does one cycle of the RNN\n",
    "        # This uses the __call__ method\n",
    "\n",
    "for t in range(num_time_steps): # Replace with tf.while_loop\n",
    "    print (\"Setting up graph for time-step %i\" %t)\n",
    "    \n",
    "    xhat = x-tf.sigmoid(canvas_previous)\n",
    "    \n",
    "    # Do the read operation\n",
    "    with tf.variable_scope(\"read_operation\",reuse=DO_SHARE):\n",
    "        read_params = tf.gather(tf.contrib.layers.fully_connected(inputs = decoder_state_previous.h, num_outputs = 5, activation_fn = None), 0)\n",
    "\n",
    "    center_coords_decoded[t] = [tf.tanh(read_params[0]),tf.tanh(read_params[1])]\n",
    "    sigma_decoded[t], stride_decoded[t], gamma_decoded[t] = read_params[2], -3.0*tf.sigmoid(read_params[3]-3), read_params[4] \n",
    "    # Initializing and range constraining the stride: http://www.wolframalpha.com/input/?i=-3*sigmoid(x-3)\n",
    "    filter_bank_X, filter_bank_Y = tf_get_filter_banks(center_coords_decoded[t], sigma_decoded[t], stride_decoded[t], N_read)\n",
    "   \n",
    "    read_result = [tf.exp(gamma_decoded[t])*tf.matmul(tf.matmul(filter_bank_Y, tf.gather(tf.reshape(x, [1,A,B]),0)), tf.transpose(filter_bank_X)), tf.exp(gamma_decoded[t])*tf.matmul(tf.matmul(filter_bank_Y, tf.gather(tf.reshape(xhat, [1,A,B]),0)), tf.transpose(filter_bank_X))] \n",
    "    \n",
    "    if attention:\n",
    "        # Update the encoder state\n",
    "        encoder_state = encode_step(input_data = tf.concat([tf.reshape(read_result, [1,N_read*N_read + N_read*N_read]), tf.reshape(decoder_state_previous.h, [1,num_units_dec])], axis=-1), network_state = encoder_state_previous)\n",
    "        # Note: encoder_state is the output of the LSTMCell's call method -- first output, then a LSTM state tuple\n",
    "    else:\n",
    "        encoder_state = encode_step(input_data = tf.concat([x,xhat], axis = -1), network_state = encoder_state_previous)\n",
    "    \n",
    "    # Sample the latents\n",
    "    with tf.variable_scope(\"latents\",reuse=DO_SHARE):\n",
    "        latent_means = tf.contrib.layers.fully_connected(encoder_state[0], num_latents, activation_fn = None)\n",
    "        latent_stds = tf.exp(tf.contrib.layers.fully_connected(encoder_state[0], num_latents, activation_fn = None))\n",
    "    \n",
    "    samples_without_mean = tf.random_normal([num_latents], mean=0, stddev=1, dtype=tf.float32)  \n",
    "    sampled_latents = latent_means + (latent_stds * samples_without_mean)\n",
    "    \n",
    "    lms[t] = latent_means\n",
    "    lss[t] = latent_stds\n",
    "    \n",
    "    # Update the decoder state\n",
    "    decoder_state = decode_step(latents = sampled_latents, network_state = decoder_state_previous)\n",
    "    \n",
    "    # Write\n",
    "    if attention:\n",
    "        with tf.variable_scope(\"write_operation_attn\",reuse=DO_SHARE):\n",
    "            writing_instruction =  tf.reshape(tf.contrib.layers.fully_connected(decoder_state[0], N_write*N_write, activation_fn = None), [N_write,N_write])\n",
    "            write_params = tf.gather(tf.contrib.layers.fully_connected(inputs = decoder_state[0], num_outputs = 5, activation_fn = None), 0)\n",
    "\n",
    "        center_coords_decoded_write[t] = [tf.tanh(write_params[0]),tf.tanh(write_params[1])]\n",
    "        sigma_decoded_write[t], stride_decoded_write[t], gamma_decoded_write[t] = write_params[2], -3.0*tf.sigmoid(write_params[3]-3), write_params[4]\n",
    "        filter_bank_X_write, filter_bank_Y_write = tf_get_filter_banks(center_coords_decoded_write[t], sigma_decoded_write[t], stride_decoded_write[t], N_write)\n",
    "        \n",
    "        writing_value = tf.exp(-1*gamma_decoded_write[t])*tf.matmul(tf.matmul(tf.transpose(filter_bank_Y_write), writing_instruction), filter_bank_X_write)\n",
    "    else:\n",
    "        with tf.variable_scope(\"write_operation_noattn\",reuse=DO_SHARE):\n",
    "            writing_instruction = tf.contrib.layers.fully_connected(decoder_state[0], A*B, activation_fn = None)\n",
    "        writing_value = writing_instruction\n",
    "                                   \n",
    "    canvas[t] =  canvas_previous + tf.reshape(writing_value, [1,A*B])\n",
    "                                   \n",
    "    # Cycle\n",
    "    encoder_state_previous = encoder_state[1]\n",
    "    decoder_state_previous = decoder_state[1]\n",
    "    canvas_previous = canvas[t]\n",
    "    \n",
    "    # To turn this on after the first cycle\n",
    "    DO_SHARE = True\n",
    "\n",
    "canvas = tf.sigmoid(canvas)\n",
    "    \n",
    "# Setting up loss function\n",
    "print(\"Setting up loss function...\")\n",
    "epsilon = 0.0000001 # A trick like this was used by Eric Jang for numerical stability, although there with cross-entropy loss -- here it avoids Inf in the log as well\n",
    "#loss_reconstruction = tf.reduce_mean(tf.squared_difference(canvas[num_time_steps-1],x)) # RMS reconstruction error in the pixel space\n",
    "o = canvas[-1]\n",
    "loss_reconstruction = tf.reduce_sum(-(x*tf.log(o+epsilon) + (1.0-x)*tf.log(1.0-o+epsilon))) # Cross entropy loss: ~probability of the data\n",
    "# I think the reason for this is similar to here: https://stats.stackexchange.com/questions/242907/why-use-binary-cross-entropy-for-generator-in-adversarial-networks/242927?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa\n",
    "loss_latent = tf.reduce_sum([0.5 * tf.reduce_sum(tf.square(lms[t]) + tf.square(lss[t]) - tf.log(tf.square(lms)+epsilon) - 1)/batch_size for t in range(num_time_steps)])\n",
    "if variational:\n",
    "    relative_weight = 1.0 # Between the reconstruction versus latent KL loss\n",
    "else:\n",
    "    relative_weight = 0.0\n",
    "loss = loss_reconstruction + relative_weight * loss_latent # this includes a manual scaling parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up the optimizer (we'll have to move this above)\n",
    "print(\"Setting up optimizer...\")\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, beta1=0.5)\n",
    "print(\"Minimizing...\")\n",
    "train_op=optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sanity check on variable shapes\n",
    "print(\"All variables...\")\n",
    "for v in tf.all_variables():\n",
    "    print(\"\\t%s : %s\" % (v.name,v.get_shape()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example run\n",
    "img = mnist.train.images[32171][:]\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "print(\"Running...\")\n",
    "l, cv, lmsout, lssout, ccd, sig, stri, ccdw, sigw, striw = sess.run([loss, canvas, lms, lss, center_coords_decoded, sigma_decoded, stride_decoded, center_coords_decoded_write, sigma_decoded_write, stride_decoded_write], feed_dict = {x:[img]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Untrained model...\")\n",
    "for t in range(len(cv)):\n",
    "    c = cv[t]\n",
    "    c_img = MNIST_row_as_image(c[0].tolist())\n",
    "    plt.figure()\n",
    "    plt.imshow(c_img, cmap = cm.Greys_r)\n",
    "    filter_bank_X, filter_bank_Y, means = np_get_filter_banks(center_coords_dec = ccd[t], sigma_dec = sig[t], stride_dec = stri[t], N = N_read)\n",
    "    filter_bank_Xw, filter_bank_Yw, meansw = np_get_filter_banks(center_coords_dec = ccdw[t], sigma_dec = sigw[t], stride_dec = striw[t], N = N_write)\n",
    "        \n",
    "    if attention:\n",
    "        scat = plt.scatter([m[0] for m in means], [m[1] for m in means], color = 'r')\n",
    "        scat2 = plt.scatter([m[0] for m in meansw], [m[1] for m in meansw], color = 'g')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Training...\")\n",
    "print(\"Attention: %r\" % attention)\n",
    "losses_log = []\n",
    "latent_losses_log = []\n",
    "\n",
    "for i in range(10000):\n",
    "    img = mnist.train.images[i][:]\n",
    "    l, t_op, ll = sess.run([loss, train_op, loss_latent], feed_dict = {x:[img]})\n",
    "    print(i)\n",
    "    losses_log.append(l)\n",
    "    latent_losses_log.append(ll)\n",
    "    if i % 50 == 0:\n",
    "        print(\"Finished %i, loss %f\" % (i,l))\n",
    "        print(\"Correct image:\")\n",
    "        img = mnist.train.images[10003][:]\n",
    "        plt.figure()\n",
    "        plt.imshow(MNIST_row_as_image(img), cmap = cm.Greys_r)\n",
    "        print(\"Running...\")\n",
    "        l, cv, lmsout, lssout, ccd, sig, stri, ccdw, sigw, striw = sess.run([loss, canvas, lms, lss, center_coords_decoded, sigma_decoded, stride_decoded, center_coords_decoded_write, sigma_decoded_write, stride_decoded_write], feed_dict = {x:[img]})\n",
    "        print(\"Drawing steps...\")\n",
    "        for t in range(len(cv)):\n",
    "            c = cv[t]\n",
    "            c_img = MNIST_row_as_image(c[0].tolist())\n",
    "            plt.figure()\n",
    "            plt.imshow(c_img, cmap = cm.Greys_r)\n",
    "            filter_bank_X, filter_bank_Y, means = np_get_filter_banks(center_coords_dec = ccd[t], sigma_dec = sig[t], stride_dec = stri[t], N = N_read)\n",
    "            filter_bank_Xw, filter_bank_Yw, meansw = np_get_filter_banks(center_coords_dec = ccdw[t], sigma_dec = sigw[t], stride_dec = striw[t], N = N_write)\n",
    "            if attention:\n",
    "                scat = plt.scatter([m[0] for m in means], [m[1] for m in means], color = 'r')\n",
    "                scat2 = plt.scatter([m[0] for m in meansw], [m[1] for m in meansw], color = 'g')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Training loss\")\n",
    "\n",
    "conv_size = 50\n",
    "def smooth(ser):\n",
    "    return np.convolve(ser, np.ones((conv_size,))/conv_size, mode='valid')\n",
    "\n",
    "plt.plot(smooth(losses_log), label = \"loss (reconstruction + latent)\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(smooth(latent_losses_log), label = \"latent loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(smooth([losses_log[k] - relative_weight*latent_losses_log[k] for k in range(len(losses_log))][:]), label = \"reconstruction loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Second example run, after a tiny bit of training\n",
    "print(\"Attention: %r\" % attention)\n",
    "print(\"Correct image:\")\n",
    "img = mnist.train.images[10004][:]\n",
    "plt.figure()\n",
    "plt.imshow(MNIST_row_as_image(img), cmap = cm.Greys_r)\n",
    "print(\"Running...\")\n",
    "l, cv, lmsout, lssout, ccd, sig, stri, ccdw, sigw, striw = sess.run([loss, canvas, lms, lss, center_coords_decoded, sigma_decoded, stride_decoded, center_coords_decoded_write, sigma_decoded_write, stride_decoded_write], feed_dict = {x:[img]})\n",
    "print(\"Drawing steps...\")\n",
    "for t in range(len(cv)):\n",
    "    c = cv[t]\n",
    "    c_img = MNIST_row_as_image(c[0].tolist())\n",
    "    plt.figure()\n",
    "    plt.imshow(c_img, cmap = cm.Greys_r)\n",
    "    filter_bank_X, filter_bank_Y, means = np_get_filter_banks(center_coords_dec = ccd[t], sigma_dec = sig[t], stride_dec = stri[t], N = N_read)\n",
    "    filter_bank_Xw, filter_bank_Yw, meansw = np_get_filter_banks(center_coords_dec = ccdw[t], sigma_dec = sigw[t], stride_dec = striw[t], N = N_write)\n",
    "    if attention:\n",
    "        scat = plt.scatter([m[0] for m in means], [m[1] for m in means], color = 'r')\n",
    "        scat2 = plt.scatter([m[0] for m in meansw], [m[1] for m in meansw], color = 'g')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Training more...\")\n",
    "losses_log = []\n",
    "latent_losses_log = []\n",
    "for i in range(10000):\n",
    "    img = mnist.train.images[10000+i][:]\n",
    "    l, t_op, ll = sess.run([loss, train_op, loss_latent], feed_dict = {x:[img]})\n",
    "    print(10000+i)\n",
    "    losses_log.append(l)\n",
    "    latent_losses_log.append(ll)\n",
    "    if i % 50 == 0:\n",
    "        print(\"Finished %i, loss %f\" % (10000+i,l))\n",
    "        print(\"Correct image:\")\n",
    "        img = mnist.train.images[31000][:]\n",
    "        plt.figure()\n",
    "        plt.imshow(MNIST_row_as_image(img), cmap = cm.Greys_r)\n",
    "        print(\"Running...\")\n",
    "        l, cv, lmsout, lssout, ccd, sig, stri, ccdw, sigw, striw = sess.run([loss, canvas, lms, lss, center_coords_decoded, sigma_decoded, stride_decoded, center_coords_decoded_write, sigma_decoded_write, stride_decoded_write], feed_dict = {x:[img]})\n",
    "        print(\"Drawing steps...\")\n",
    "        for t in range(len(cv)):\n",
    "            c = cv[t]\n",
    "            c_img = MNIST_row_as_image(c[0].tolist())\n",
    "            plt.figure()\n",
    "            plt.imshow(c_img, cmap = cm.Greys_r)\n",
    "            filter_bank_X, filter_bank_Y, means = np_get_filter_banks(center_coords_dec = ccd[t], sigma_dec = sig[t], stride_dec = stri[t], N = N_read)\n",
    "            filter_bank_Xw, filter_bank_Yw, meansw = np_get_filter_banks(center_coords_dec = ccdw[t], sigma_dec = sigw[t], stride_dec = striw[t], N = N_write)\n",
    "            if attention:\n",
    "                scat = plt.scatter([m[0] for m in means], [m[1] for m in means], color = 'r')\n",
    "                scat2 = plt.scatter([m[0] for m in meansw], [m[1] for m in meansw], color = 'g')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Training loss\")\n",
    "\n",
    "conv_size = 50\n",
    "def smooth(ser):\n",
    "    return np.convolve(ser, np.ones((conv_size,))/conv_size, mode='valid')\n",
    "\n",
    "plt.plot(smooth(losses_log), label = \"loss (reconstruction + latent)\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(smooth(latent_losses_log), label = \"latent loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(smooth([losses_log[k] - relative_weight*latent_losses_log[k] for k in range(len(losses_log))][:]), label = \"reconstruction loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Attention: %r\" % attention)\n",
    "print(\"Correct image:\")\n",
    "img = mnist.train.images[10004][:]\n",
    "plt.figure()\n",
    "plt.imshow(MNIST_row_as_image(img), cmap = cm.Greys_r)\n",
    "print(\"Running...\")\n",
    "l, cv, lmsout, lssout, ccd, sig, stri, ccdw, sigw, striw = sess.run([loss, canvas, lms, lss, center_coords_decoded, sigma_decoded, stride_decoded, center_coords_decoded_write, sigma_decoded_write, stride_decoded_write], feed_dict = {x:[img]})\n",
    "print(\"Drawing steps...\")\n",
    "for t in range(len(cv)):\n",
    "    c = cv[t]\n",
    "    c_img = MNIST_row_as_image(c[0].tolist())\n",
    "    plt.figure()\n",
    "    plt.imshow(c_img, cmap = cm.Greys_r)\n",
    "    filter_bank_X, filter_bank_Y, means = np_get_filter_banks(center_coords_dec = ccd[t], sigma_dec = sig[t], stride_dec = stri[t], N = N_read)\n",
    "    filter_bank_Xw, filter_bank_Yw, meansw = np_get_filter_banks(center_coords_dec = ccdw[t], sigma_dec = sigw[t], stride_dec = striw[t], N = N_write)\n",
    "    if attention:\n",
    "        scat = plt.scatter([m[0] for m in means], [m[1] for m in means], color = 'r')\n",
    "        scat2 = plt.scatter([m[0] for m in meansw], [m[1] for m in meansw], color = 'g')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Attention: %r\" % attention)\n",
    "print(\"Correct image:\")\n",
    "img = mnist.train.images[31001][:]\n",
    "plt.figure()\n",
    "plt.imshow(MNIST_row_as_image(img), cmap = cm.Greys_r)\n",
    "print(\"Running...\")\n",
    "l, cv, lmsout, lssout, ccd, sig, stri, ccdw, sigw, striw = sess.run([loss, canvas, lms, lss, center_coords_decoded, sigma_decoded, stride_decoded, center_coords_decoded_write, sigma_decoded_write, stride_decoded_write], feed_dict = {x:[img]})\n",
    "print(\"Drawing steps...\")\n",
    "for t in range(len(cv)):\n",
    "    c = cv[t]\n",
    "    c_img = MNIST_row_as_image(c[0].tolist())\n",
    "    plt.figure()\n",
    "    plt.imshow(c_img, cmap = cm.Greys_r)\n",
    "    filter_bank_X, filter_bank_Y, means = np_get_filter_banks(center_coords_dec = ccd[t], sigma_dec = sig[t], stride_dec = stri[t], N = N_read)\n",
    "    filter_bank_Xw, filter_bank_Yw, meansw = np_get_filter_banks(center_coords_dec = ccdw[t], sigma_dec = sigw[t], stride_dec = striw[t], N = N_write)\n",
    "    if attention:\n",
    "        scat = plt.scatter([m[0] for m in means], [m[1] for m in means], color = 'r')\n",
    "        scat2 = plt.scatter([m[0] for m in meansw], [m[1] for m in meansw], color = 'g')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
